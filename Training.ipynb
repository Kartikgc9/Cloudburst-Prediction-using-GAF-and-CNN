{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyts.image import GramianAngularField\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import layers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import InputLayer, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 6, 256, 256)\n",
      "(96, 6, 256, 256)\n",
      "(113, 6, 256, 256)\n",
      "(113,)\n"
     ]
    }
   ],
   "source": [
    "## Load the data\n",
    "cloudburst_data = np.load('CB12.npy')\n",
    "non_cloudburst_data = np.load('NB.npy')\n",
    "\n",
    "print(cloudburst_data.shape)\n",
    "print(non_cloudburst_data.shape)\n",
    "\n",
    "# Combine the cloudburst and non-cloudburst data into one array\n",
    "X = np.concatenate((cloudburst_data, non_cloudburst_data))\n",
    "\n",
    "# Create a target vector (1 for cloudburst, 0 for non-cloudburst)\n",
    "y = np.concatenate((np.ones(cloudburst_data.shape[0]), np.zeros(non_cloudburst_data.shape[0])))\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_index = np.random.permutation(X.shape[0])\n",
    "X = X[shuffle_index]\n",
    "y = y[shuffle_index]\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "79/79 [==============================] - 48s 594ms/step - loss: 2707.3738 - accuracy: 0.7722 - val_loss: 2627.8445 - val_accuracy: 0.8824\n",
      "Epoch 2/50\n",
      "79/79 [==============================] - 34s 436ms/step - loss: 2551.9939 - accuracy: 0.8101 - val_loss: 2474.7920 - val_accuracy: 0.8824\n",
      "Epoch 3/50\n",
      "79/79 [==============================] - 34s 435ms/step - loss: 2401.2346 - accuracy: 0.8101 - val_loss: 2326.3962 - val_accuracy: 0.8824\n",
      "Epoch 4/50\n",
      "79/79 [==============================] - 35s 438ms/step - loss: 2255.0806 - accuracy: 0.8481 - val_loss: 2182.5959 - val_accuracy: 0.8824\n",
      "Epoch 5/50\n",
      "79/79 [==============================] - 34s 430ms/step - loss: 2113.5317 - accuracy: 0.8228 - val_loss: 2043.3925 - val_accuracy: 0.8824\n",
      "Epoch 6/50\n",
      "79/79 [==============================] - 33s 412ms/step - loss: 1976.6057 - accuracy: 0.8481 - val_loss: 1908.8135 - val_accuracy: 0.8824\n",
      "Epoch 7/50\n",
      "79/79 [==============================] - 35s 439ms/step - loss: 1844.2257 - accuracy: 0.8608 - val_loss: 1778.7965 - val_accuracy: 0.8824\n",
      "Epoch 8/50\n",
      "79/79 [==============================] - 36s 460ms/step - loss: 1716.4888 - accuracy: 0.8734 - val_loss: 1653.4218 - val_accuracy: 0.8529\n",
      "Epoch 9/50\n",
      "79/79 [==============================] - 34s 431ms/step - loss: 1593.2928 - accuracy: 0.8987 - val_loss: 1532.6497 - val_accuracy: 0.8824\n",
      "Epoch 10/50\n",
      "79/79 [==============================] - 32s 405ms/step - loss: 1474.7980 - accuracy: 0.8608 - val_loss: 1416.3667 - val_accuracy: 0.8824\n",
      "Epoch 11/50\n",
      "79/79 [==============================] - 32s 398ms/step - loss: 1360.8378 - accuracy: 0.9241 - val_loss: 1304.7961 - val_accuracy: 0.8529\n",
      "Epoch 12/50\n",
      "79/79 [==============================] - 31s 395ms/step - loss: 1251.4567 - accuracy: 0.9241 - val_loss: 1197.6946 - val_accuracy: 0.8824\n",
      "Epoch 13/50\n",
      "79/79 [==============================] - 35s 446ms/step - loss: 1146.6406 - accuracy: 0.9494 - val_loss: 1095.2854 - val_accuracy: 0.8824\n",
      "Epoch 14/50\n",
      "79/79 [==============================] - 39s 487ms/step - loss: 1046.5128 - accuracy: 0.9114 - val_loss: 997.8496 - val_accuracy: 0.8235\n",
      "Epoch 15/50\n",
      "79/79 [==============================] - 34s 436ms/step - loss: 950.9155 - accuracy: 0.9241 - val_loss: 904.2999 - val_accuracy: 0.8529\n",
      "Epoch 16/50\n",
      "79/79 [==============================] - 36s 451ms/step - loss: 859.9247 - accuracy: 0.9367 - val_loss: 815.4877 - val_accuracy: 0.8824\n",
      "Epoch 17/50\n",
      "79/79 [==============================] - 37s 464ms/step - loss: 773.4913 - accuracy: 0.9367 - val_loss: 731.3945 - val_accuracy: 0.8824\n",
      "Epoch 18/50\n",
      "79/79 [==============================] - 34s 429ms/step - loss: 691.7383 - accuracy: 0.9114 - val_loss: 651.9619 - val_accuracy: 0.8824\n",
      "Epoch 19/50\n",
      "79/79 [==============================] - 39s 487ms/step - loss: 614.4575 - accuracy: 0.9620 - val_loss: 576.9936 - val_accuracy: 0.8824\n",
      "Epoch 20/50\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 541.8106 - accuracy: 0.9494 - val_loss: 506.6694 - val_accuracy: 0.8824\n",
      "Epoch 21/50\n",
      "79/79 [==============================] - 38s 479ms/step - loss: 473.7778 - accuracy: 0.9241 - val_loss: 440.9685 - val_accuracy: 0.8824\n",
      "Epoch 22/50\n",
      "79/79 [==============================] - 35s 443ms/step - loss: 410.3026 - accuracy: 0.9241 - val_loss: 379.8229 - val_accuracy: 0.8824\n",
      "Epoch 23/50\n",
      "79/79 [==============================] - 41s 516ms/step - loss: 351.4448 - accuracy: 0.9494 - val_loss: 323.2396 - val_accuracy: 0.8824\n",
      "Epoch 24/50\n",
      "79/79 [==============================] - 42s 536ms/step - loss: 297.1596 - accuracy: 0.9367 - val_loss: 271.2985 - val_accuracy: 0.8824\n",
      "Epoch 25/50\n",
      "79/79 [==============================] - 42s 527ms/step - loss: 247.4584 - accuracy: 0.9620 - val_loss: 223.8768 - val_accuracy: 0.8824\n",
      "Epoch 26/50\n",
      "79/79 [==============================] - 38s 480ms/step - loss: 202.3459 - accuracy: 0.9114 - val_loss: 181.2390 - val_accuracy: 0.8824\n",
      "Epoch 27/50\n",
      "79/79 [==============================] - 33s 413ms/step - loss: 161.8071 - accuracy: 0.9241 - val_loss: 142.9528 - val_accuracy: 0.8824\n",
      "Epoch 28/50\n",
      "79/79 [==============================] - 33s 415ms/step - loss: 125.9415 - accuracy: 0.8608 - val_loss: 109.3148 - val_accuracy: 0.8824\n",
      "Epoch 29/50\n",
      "79/79 [==============================] - 34s 425ms/step - loss: 94.5908 - accuracy: 0.8861 - val_loss: 80.1698 - val_accuracy: 0.8824\n",
      "Epoch 30/50\n",
      "79/79 [==============================] - 36s 454ms/step - loss: 67.8446 - accuracy: 0.8608 - val_loss: 55.9265 - val_accuracy: 0.8824\n",
      "Epoch 31/50\n",
      "79/79 [==============================] - 42s 535ms/step - loss: 45.6611 - accuracy: 0.8354 - val_loss: 35.8996 - val_accuracy: 0.8824\n",
      "Epoch 32/50\n",
      "79/79 [==============================] - 43s 540ms/step - loss: 28.0427 - accuracy: 0.8608 - val_loss: 20.6144 - val_accuracy: 0.8824\n",
      "Epoch 33/50\n",
      "79/79 [==============================] - 37s 471ms/step - loss: 15.0961 - accuracy: 0.8228 - val_loss: 10.2555 - val_accuracy: 0.8824\n",
      "Epoch 34/50\n",
      "79/79 [==============================] - 38s 481ms/step - loss: 6.7662 - accuracy: 0.7595 - val_loss: 3.6921 - val_accuracy: 0.8824\n",
      "Epoch 35/50\n",
      "79/79 [==============================] - 41s 514ms/step - loss: 2.7366 - accuracy: 0.7848 - val_loss: 1.9250 - val_accuracy: 0.8824\n",
      "Epoch 36/50\n",
      "79/79 [==============================] - 41s 520ms/step - loss: 2.1577 - accuracy: 0.7722 - val_loss: 3.1267 - val_accuracy: 0.1176\n",
      "Epoch 37/50\n",
      "79/79 [==============================] - 41s 515ms/step - loss: 2.1371 - accuracy: 0.7848 - val_loss: 1.8020 - val_accuracy: 0.8824\n",
      "Epoch 38/50\n",
      "79/79 [==============================] - 41s 515ms/step - loss: 1.9926 - accuracy: 0.7722 - val_loss: 2.1958 - val_accuracy: 0.8824\n",
      "Epoch 39/50\n",
      "79/79 [==============================] - 41s 516ms/step - loss: 2.0038 - accuracy: 0.7848 - val_loss: 1.8313 - val_accuracy: 0.8824\n",
      "Epoch 40/50\n",
      "79/79 [==============================] - 41s 515ms/step - loss: 2.0070 - accuracy: 0.7342 - val_loss: 2.7206 - val_accuracy: 0.1176\n",
      "Epoch 41/50\n",
      "79/79 [==============================] - 40s 504ms/step - loss: 1.9943 - accuracy: 0.7722 - val_loss: 2.0577 - val_accuracy: 0.8824\n",
      "Epoch 42/50\n",
      "79/79 [==============================] - 42s 530ms/step - loss: 1.9841 - accuracy: 0.7468 - val_loss: 1.6140 - val_accuracy: 0.8824\n",
      "Epoch 43/50\n",
      "79/79 [==============================] - 40s 505ms/step - loss: 1.8993 - accuracy: 0.8101 - val_loss: 1.6039 - val_accuracy: 0.8824\n",
      "Epoch 44/50\n",
      "79/79 [==============================] - 42s 531ms/step - loss: 1.9332 - accuracy: 0.7848 - val_loss: 1.6742 - val_accuracy: 0.8824\n",
      "Epoch 45/50\n",
      "79/79 [==============================] - 40s 510ms/step - loss: 1.9116 - accuracy: 0.7848 - val_loss: 1.9620 - val_accuracy: 0.8824\n",
      "Epoch 46/50\n",
      "79/79 [==============================] - 41s 513ms/step - loss: 1.8465 - accuracy: 0.7848 - val_loss: 1.8734 - val_accuracy: 0.8824\n",
      "Epoch 47/50\n",
      "79/79 [==============================] - 40s 508ms/step - loss: 1.9026 - accuracy: 0.7975 - val_loss: 1.7704 - val_accuracy: 0.8824\n",
      "Epoch 48/50\n",
      "79/79 [==============================] - 39s 492ms/step - loss: 1.8979 - accuracy: 0.8354 - val_loss: 1.6760 - val_accuracy: 0.8824\n",
      "Epoch 49/50\n",
      "79/79 [==============================] - 39s 494ms/step - loss: 1.8558 - accuracy: 0.7848 - val_loss: 1.5978 - val_accuracy: 0.8824\n",
      "Epoch 50/50\n",
      "79/79 [==============================] - 40s 504ms/step - loss: 1.9196 - accuracy: 0.8228 - val_loss: 1.8204 - val_accuracy: 0.8824\n",
      "Optimizer: sgd, Kernel Size: (1, 1), Pooling Size: (1, 1), Learning Rate: 0.0001\n",
      "Training accuracy: 0.8227848410606384, Validation accuracy: 0.8823529481887817\n",
      "--------------------------------------------------\n",
      "4/4 [==============================] - 1s 41ms/step\n",
      "Confusion Matrix:\n",
      "[[96  0]\n",
      " [17  0]]\n",
      "Accuracy: 0.8495575221238938\n",
      "Error for hyperparameter combination optimizer=sgd, kernel_size=(1, 1), pooling_size=(1, 1), learning_rate=0.0001: [Errno 2] No such file or directory: 'D:\\\\TEST12.npy'\n",
      "Epoch 1/50\n",
      "79/79 [==============================] - 97s 1s/step - loss: 2410.3423 - accuracy: 0.7468 - val_loss: 2044.2063 - val_accuracy: 0.8824\n",
      "Epoch 2/50\n",
      " 1/79 [..............................] - ETA: 1:27 - loss: 2044.6134 - accuracy: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "optimizers = ['sgd']\n",
    "kernel_sizes = [(1, 1), (2, 2), (3, 3)]\n",
    "pooling_sizes = [(1, 1), (2, 2), (3, 3)]\n",
    "learning_rates = [0.0001, 0.0005, 0.001]\n",
    "\n",
    "for i, opt in enumerate(optimizers):\n",
    "    for j, k_size in enumerate(kernel_sizes):\n",
    "        for l, p_size in enumerate(pooling_sizes):\n",
    "            for m, lr in enumerate(learning_rates):\n",
    "                # Get the current TensorFlow session\n",
    "                sess = tf.compat.v1.get_default_session()\n",
    "\n",
    "                # Close the session to free up the GPU memory\n",
    "                if sess is not None:\n",
    "                    sess.close()\n",
    "\n",
    "                # Reset the TensorFlow graph\n",
    "                tf.compat.v1.reset_default_graph()\n",
    "\n",
    "                \n",
    "                try:\n",
    "                    # Create a new model for each hyperparameter combination\n",
    "                    model = Sequential(name=f'sequential_{i}_{j}_{l}_{m}')\n",
    "                    model.add(InputLayer(input_shape=(6, 256, 256)))\n",
    "                    model.add(Conv2D(filters=128, kernel_size=k_size, activation='relu', padding='same'))\n",
    "                    model.add(MaxPooling2D(pool_size=p_size, padding='same'))\n",
    "                    model.add(Conv2D(filters=256, kernel_size=k_size, activation='relu', padding='same'))\n",
    "                    model.add(MaxPooling2D(pool_size=(1, 1), padding='same'))\n",
    "                    model.add(Conv2D(filters=512, kernel_size=k_size, activation='relu', padding='same'))\n",
    "                    model.add(MaxPooling2D(pool_size=p_size, padding='same'))\n",
    "                    model.add(Flatten())\n",
    "                    model.add(Dense(units=256, activation='relu', kernel_regularizer='l1_l2'))\n",
    "                    model.add(Dropout(rate=0.5))\n",
    "                    model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "                    optimizer = None\n",
    "                    if opt == 'adam':\n",
    "                        optimizer = Adam(learning_rate=lr)\n",
    "                    elif opt == 'sgd':\n",
    "                        optimizer = SGD(learning_rate=lr)\n",
    "                    elif opt == 'rmsprop':\n",
    "                        optimizer = RMSprop(learning_rate=lr)\n",
    "\n",
    "                    # Compile the model with binary cross-entropy loss function\n",
    "                    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "                    # Train the model on your data with 50 epochs and batch size of 1\n",
    "                    history = model.fit(X, y, epochs=50, batch_size=1, validation_split=0.3)\n",
    "\n",
    "                    # Print the output of each combination\n",
    "                    print(f\"Optimizer: {opt}, Kernel Size: {k_size}, Pooling Size: {p_size}, Learning Rate: {lr}\")\n",
    "                    print(f\"Training accuracy: {history.history['accuracy'][-1]}, Validation accuracy: {history.history['val_accuracy'][-1]}\")\n",
    "                    print(\"-\" * 50)\n",
    "\n",
    "                    # Calculate and print the confusion matrix\n",
    "                    y_pred = np.round(model.predict(X)).flatten()\n",
    "                    y_true = y.flatten()\n",
    "                    cm = confusion_matrix(y_true, y_pred)\n",
    "                    print(\"Confusion Matrix:\")\n",
    "                    print(cm)\n",
    "\n",
    "                    accuracy = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
    "                    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "                    test = np.load('D:\\\\TEST12.npy')\n",
    "                    print(test.shape)\n",
    "                    prediction = model.predict(test)\n",
    "\n",
    "                    # Multiply the output by 100 and convert it to integers\n",
    "                    prediction_int = (prediction * 100).astype(int)\n",
    "\n",
    "                    # Print the result\n",
    "                    print(prediction_int)\n",
    "\n",
    "                    \n",
    "                    model.save(f'D:\\\\Models\\\\sequential_{i}_{j}_{l}_{m}.h5')\n",
    "\n",
    "                except Exception as e:\n",
    "                    # If there's an error, print a message and continue to the next combination\n",
    "                    print(f\"Error for hyperparameter combination optimizer={opt}, kernel_size={k_size}, pooling_size={p_size}, learning_rate={lr}: {e}\")\n",
    "                    continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 72ms/step\n",
      "Confusion Matrix:\n",
      "[[95  1]\n",
      " [ 2 15]]\n",
      "Accuracy: 0.9734513274336283\n"
     ]
    }
   ],
   "source": [
    "# Calculate and print the confusion matrix\n",
    "y_pred = np.round(model.predict(X)).flatten()\n",
    "y_true = y.flatten()\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n",
    "\n",
    "accuracy = (cm[0,0]+cm[1,1])/(cm[0,0]+cm[0,1]+cm[1,0]+cm[1,1])\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "model.save('latest_6_better2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('latest_6_better.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 256, 256)\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "[[ 5]\n",
      " [17]\n",
      " [ 0]\n",
      " [ 0]\n",
      " [ 0]]\n"
     ]
    }
   ],
   "source": [
    "test = np.load('D:\\\\TEST6.npy')\n",
    "print(test.shape)\n",
    "prediction = model.predict(test)\n",
    "\n",
    "# Multiply the output by 100 and convert it to integers\n",
    "prediction_int = (prediction * 100).astype(int)\n",
    "\n",
    "# Print the result\n",
    "print(prediction_int)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c3ae5b30a890397a3cbc9b8d8713d5c1cc299c9260435bdbf8473a86bc666a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

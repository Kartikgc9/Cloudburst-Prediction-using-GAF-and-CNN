{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyts.image import GramianAngularField\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.keras import layers\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('Model6.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_GAF(data):\n",
    "    feature_names = [\"RAIN FALL CUM. SINCE 0300 UTC (mm)\",\"TEMP. ('C)\",\"RH (%)\",\"WIND SPEED 10 m (Kt)\",\"SLP (hPa)\",\"MSLP (hPa / gpm)\"]\n",
    "\n",
    "    gaf_images = []\n",
    "    for feature_name in feature_names:\n",
    "        # Get the data for the current feature\n",
    "        data_feature = data[0][feature_name]\n",
    "        # Fill NaN values with the mean of the column\n",
    "        data_feature.fillna(data_feature.mean(), inplace=True)\n",
    "        # Convert the data to a numpy array\n",
    "        data_feature = data_feature.values\n",
    "        # Create a Gramian Angular Field object\n",
    "        gaf = GramianAngularField(image_size=256, method='summation')\n",
    "        # Convert the data to a GAF image\n",
    "        image = gaf.transform([data_feature])\n",
    "        gaf_images.append(image[0])\n",
    "    return gaf_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = datetime.date.today() #Current Date\n",
    "prev_date = current_date - datetime.timedelta(days=6) #Date 6 Days before\n",
    "# Get the Location Information\n",
    "state = \"UTTARAKHAND\"\n",
    "district = input(\"Enter the district: \") #DEHRADUN\n",
    "station = input(\"Enter the station: \") #MUSSOORIE(UKG)_UKG\n",
    "#Get the Data from IMD\n",
    "url = \"http://aws.imd.gov.in:8091/AWS/dataview.php?a=AWS&b={}&c={}&d={}&e={}&f={}&g=ALL_HOUR&h=ALL_MINUTE\".format(state,district,station,prev_date, current_date)\n",
    "df_list = pd.read_html(url)\n",
    "#Generate the GAF\n",
    "gaf_images = generate_GAF(df_list)\n",
    "gaf_data = np.array([gaf_images])\n",
    "#Loading the 6 Hour Model and make prediction\n",
    "from keras.models import load_model\n",
    "model = load_model('Model6.h5')\n",
    "prediction = model.predict(gaf_data)\n",
    "print(\"probability of cloudburst :- \"+ (str)((prediction*100)[0][0]) +\"%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
